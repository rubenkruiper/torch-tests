{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic steps of setting up a pytorch model\n",
    "Preprocessing of data is outside the scope of this tutorial. However, the input is expect to be some torch tensor type. Therefore there are some introductory tensor and torch Variable manipulations listed below.\n",
    "1. __Working with Torch tensors__ \n",
    "2. __Working with Torch Variables__ \n",
    "3. __Computing the gradients:__ using Torch Variables\n",
    "4. __Loss function and Optimizer:__ Logistic Regression example (Cross Entropy)\n",
    "5. __Data__: Using the pytorch dataloader class\n",
    "\n",
    "6. __Building a model__:\n",
    "  * __STEP 1 - Define model__\n",
    "  * __STEP 2 - Instantiate model__ \n",
    "  * __STEP 3 - Loss and optimiser __ \n",
    "  * __STEP 4 - Train __ using the given loss function and optimiser\n",
    "  * __STEP 5 - Predict__ use the trained network to make predictions on unseen input. Subsequently calculate the losses, accuracy, etc..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Working with torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor as seed 0: \n",
      " 0.5488  0.5928\n",
      " 0.7152  0.8443\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Different random tensor without seed 0: \n",
      " 0.6028  0.8579\n",
      " 0.5449  0.8473\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Same tensor as the first one, because we use seed 0: \n",
      " 0.5488  0.5928\n",
      " 0.7152  0.8443\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# every seed produces the same random array\n",
    "torch.manual_seed(0)\n",
    "tensor_1 = torch.rand(2,2)\n",
    "\n",
    "tensor_2 = torch.rand(2,2)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "tensor_3 = torch.rand(2,2)\n",
    "\n",
    "print('Random tensor as seed 0:', tensor_1)\n",
    "print('Different random tensor without seed 0:',tensor_2)\n",
    "print('Same tensor as the first one, because we use seed 0:',tensor_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor as seed 0: \n",
      " 0.6028  0.8579\n",
      " 0.5449  0.8473\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Random tensor as seed 0: \n",
      " 0.4237  0.6236\n",
      " 0.6459  0.3844\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    tensor_4 = torch.rand(2,2).cuda()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    tensor_5 = torch.rand(2,2).cuda()\n",
    "    \n",
    "print('Random tensor as seed 0:', tensor_4)\n",
    "print('Random tensor as seed 0:', tensor_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n",
      "<class 'torch.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "# Tensors on CPU vs GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor_1 = tensor_1.cuda()  # convert to gpu tensor with .cuda()\n",
    "\n",
    "print(type(tensor_1))\n",
    "\n",
    "tensor_1 = tensor_1.cpu()  # back to CPU with .cpu()\n",
    "print(type(tensor_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (re)size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "\n",
      " 0.5488  0.5928\n",
      " 0.7152  0.8443\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "torch.Size([4])\n",
      "\n",
      " 0.5488\n",
      " 0.5928\n",
      " 0.7152\n",
      " 0.8443\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tensor_1.size())\n",
    "print(tensor_1)\n",
    "print(tensor_1.view(4).size())\n",
    "print(tensor_1.view(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### inplace is faster due to memory efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.25 µs ± 42.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tensor_4 - tensor_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.79 µs ± 72.8 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tensor_4.sub(tensor_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3 µs ± 6.72 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit tensor_4.sub_(tensor_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_1.size()) \n",
    "print(type(tensor_4)) # size works the same on cuda tensors\n",
    "print(tensor_4.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "\n",
      " 0.9864  0.8904\n",
      " 1.6070  0.9010\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tensor_4.add(tensor_1.cuda())) # to add two tensor, they have to be the same type\n",
    "print(tensor_1.add(torch.rand(2,2).float())) # both GPU/CPU and float/long/double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "\n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tensor_4.sub(tensor_5))\n",
    "print(tensor_4)                 # sub subtracts tensor_4 with tensor_5 == tensor_4 - tensor_5\n",
    "print(tensor_4.sub_(tensor_5))\n",
    "print(tensor_4)                 # sub_ replaces tensor_4 with tensor_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### multiply elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_4: \n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "tensor_5: \n",
      " 0.4237  0.6236\n",
      " 0.6459  0.3844\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Multiply elementwise: \n",
      "1.00000e+05 *\n",
      " -1.4629 -3.1606\n",
      " -3.4042 -1.2002\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Multiply elementwise: \n",
      "1.00000e+05 *\n",
      " -1.4629 -3.1606\n",
      " -3.4042 -1.2002\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Multiply inplace: \n",
      "1.00000e+05 *\n",
      " -1.4629 -3.1606\n",
      " -3.4042 -1.2002\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('tensor_4:',tensor_4)\n",
    "print('tensor_5:',tensor_5)\n",
    "# mul multiplies tensor_4 with tensor_5 == tensor_4 - tensor_5\n",
    "print('Multiply elementwise:',tensor_4.mul(tensor_5))    \n",
    "print('Multiply elementwise:',tensor_4 * tensor_5)\n",
    "    # mul_ without using additional memory \n",
    "print('Multiply inplace:',tensor_4.mul_(tensor_5))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### division elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_4: \n",
      "1.00000e+05 *\n",
      " -1.4629 -3.1606\n",
      " -3.4042 -1.2002\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "tensor_5: \n",
      " 0.4237  0.6236\n",
      " 0.6459  0.3844\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Divide elementwise: \n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Divide elementwise: \n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n",
      "Divide inplace: \n",
      "1.00000e+05 *\n",
      " -3.4531 -5.0686\n",
      " -5.2706 -3.1224\n",
      "[torch.cuda.FloatTensor of size 2x2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('tensor_4:',tensor_4)\n",
    "print('tensor_5:',tensor_5)\n",
    "# mul multiplies tensor_4 with tensor_5 == tensor_4 - tensor_5\n",
    "print('Divide elementwise:',tensor_4.div(tensor_5))    \n",
    "print('Divide elementwise:',tensor_4 / tensor_5)\n",
    "    # mul_ without using additional memory \n",
    "print('Divide inplace:',tensor_4.div_(tensor_5))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: \n",
      "1.00000e+05 *\n",
      " -4.3618\n",
      " -4.0955\n",
      "[torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "\n",
      "std deviation: \n",
      "1.00000e+05 *\n",
      "  1.2852\n",
      "  1.3762\n",
      "[torch.cuda.FloatTensor of size 2 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mean\n",
    "print('mean:', tensor_4.mean(dim=0))\n",
    "\n",
    "# standard deviation\n",
    "print('std deviation:', tensor_4.std(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Working with torch Variables\n",
    "* A variable wraps a Tensor, this enables accumulation of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_a = Variable(torch.ones(2,2), requires_grad=True)\n",
    "var_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_b = Variable(torch.ones(2,2), requires_grad=True)\n",
    "print(var_a + var_b)\n",
    "# same add, sub, mul, div operations can be applied \n",
    "print(torch.mul(var_a, var_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mul_ only supports scalar multiplication",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bcc61c2ed5cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# But not in place! Why?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Because \"mul_ only supports scalar multiplication\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmul_\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMulConstant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mul_ only supports scalar multiplication\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mul_ only supports scalar multiplication"
     ]
    }
   ],
   "source": [
    "# But not in place! Why?\n",
    "# Because \"mul_ only supports scalar multiplication\"\n",
    "print(var_a.mul_(var_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Gradients\n",
    "\n",
    "requires_grad enables calculation of gradients for Variables\n",
    "* Define original equation\n",
    "* Substitute equation with x\n",
    "* Reduce to scalar output using mean > o\n",
    "* Calculate gradients > o.backward()\n",
    "* Access the gradients using x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(2), requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 20\n",
       " 20\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 5 * (x + 1) ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 20\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = (1/2) * torch.sum(y)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# calculate the gradients for variables involved in o\n",
    "print(o.backward())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 10\n",
       " 10\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the gradients are stored in the Variable\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 10\n",
       " 10\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.backward(torch.FloatTensor([1.0,1.0]))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Loss function and optimizer\n",
    "######  Logistic Regression example with Pytorch\n",
    "Bring together some of the previously introduced ideas in a simple application\n",
    " \n",
    "* **Linear function**:\n",
    "  * $y = A X + \\beta $\n",
    "  * with matrix $A$ the weights and $\\beta$ the bias \n",
    "    * dimensions of $A$: *output_dim x input_dim*\n",
    "    * dimensions of $\\beta$: *output_dim x 1*\n",
    "\n",
    "$g = \\frac{1}{1+e^{-y}} = \\frac{1}{1+e^{A X + \\beta}} \\to $ estimated probability that $y = 1$ given $x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Optimising using Cross-entropy $D()$***\n",
    "\n",
    "$D(S,L) = L * log(S)-(1-L) *log(1-S)$\n",
    "* if $ L = 0 $ (for a specific label)\n",
    "  * $D(S,O) = -log(1-S)$\n",
    "    * $-log(1-S)$ : less positive if $S \\to 0$\n",
    "    * $-log(1-S)$ : more positive if $S \\to 1$ (bigger loss!)\n",
    "* if $ L = 1 $ (for a specific label)\n",
    "  * $D(S,1) = -log(S)$\n",
    "    * $-log(S)$ : less negative if $S \\to 1$\n",
    "    * $-log(S)$ : more negative if $S \\to 0$ (bigger loss!)\n",
    "    \n",
    "**Goal** is to minimise the cross entropy loss\n",
    "* $L = \\frac{1}{N}\\sum_i{D(g(Ax_i+b), L_i)}$\n",
    "  * minimise the overall distance D \n",
    "  * linear function $y \\to$ logistic function $S = g(y) \\to$ cross entropy function $D(S,L)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-log(1-S) with S near 0, very small:\n",
      " 9.999999722180686e-10\n",
      "-log(1-S) with S near 1, relatively big:\n",
      " 20.723265865228342\n",
      "log(S) with S near 1, very small:\n",
      " -9.999999722180686e-10\n",
      "log(S) with S near 0, relatively big:\n",
      " -20.72326583694641\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print('-log(1-S) with S near 0, very small:\\n',-math.log(1-.000000001))\n",
    "print('-log(1-S) with S near 1, relatively big:\\n',-math.log(1-.999999999))\n",
    "\n",
    "print('log(S) with S near 1, very small:\\n',math.log(.999999999))\n",
    "print('log(S) with S near 0, relatively big:\\n',math.log(.000000001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 -  Data using the pytorch dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# vision dataset imports\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image with 28 by 28 pixels\n",
    "train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label for the first image\n",
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = int(n_iters / (len(train_dataset) / batch_size))\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check iterability of trainingset\n",
    "import collections\n",
    "isinstance(train_loader, collections.Iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1 - CREATE THE MODEL CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Logreg(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Logreg, self).__init__()\n",
    "        # linear layer\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2 - INSTANTIATE THE MODEL CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dimensionality has to be the same as the image size!\n",
    "input_dim = 28 * 28\n",
    "# labels 0-9\n",
    "output_dim = 10\n",
    "\n",
    "model = Logreg(input_dim, output_dim * batch_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 3 - LOSS AND OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# how are you updating the parameters for every epoch?\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f048db3f0a0>\n",
      "2\n",
      "alpha:\n",
      " torch.Size([10, 784])\n",
      "beta:\n",
      " torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# print the parameters \n",
    "print(model.parameters())\n",
    "print(len(list(model.parameters()))) # amount of layers\n",
    "\n",
    "# FC 1 parameters\n",
    "print('alpha:\\n',list(model.parameters())[0].size()) # linear layer parameters\n",
    "# FC 1 bias parameters\n",
    "print('beta:\\n',list(model.parameters())[1].size()) # output layer parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 4 - TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "# print sizes of shizzle if the model doesn't like you\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    if i == 1:\n",
    "        print(images.view(-1,28*28).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500 \t Loss 0.6911 \t Accuracy: 86.34833333333333\n",
      "Iteration: 1000 \t Loss 0.6799 \t Accuracy: 86.46666666666667\n",
      "Iteration: 1500 \t Loss 0.7793 \t Accuracy: 86.56833333333333\n",
      "Iteration: 2000 \t Loss 0.6045 \t Accuracy: 86.61\n",
      "Iteration: 2500 \t Loss 0.4437 \t Accuracy: 86.715\n",
      "Iteration: 3000 \t Loss 0.6233 \t Accuracy: 86.82166666666667\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # convert input data to torch Variable\n",
    "        if torch.cuda.is_available():\n",
    "            # .cuda() has to be applied to the Tensor, not the Variable!\n",
    "            images = Variable(images.view(-1,28*28).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1,28*28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward run to get outputs\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate loss w.r.t labels (Softmax and CrossEntropy in a single step)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "        # compute the accuracy\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.view(-1,28*28).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.view(-1,28*28))\n",
    "\n",
    "                # Forward pass to get outputs\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the arg max                      \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            print('Iteration: {} \\t Loss {:.4f} \\t Accuracy: {}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 5 - PREDICT LABELS FOR TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-233-8bd3381180cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# seems like a lot of additional work to move back and forth from/to gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# seems like a lot of additional work to move back and forth from/to gpu\n",
    "if torch.cuda.is_available:\n",
    "    predicted = model(Variable(test_loader.items().view(-1,28*28).cuda())).cpu().data.numpy()\n",
    "else:\n",
    "    predicted = model(Variable(test_loader[:][:]).data.numpy())\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.],\n",
       "       [  3.],\n",
       "       [  5.],\n",
       "       [  7.],\n",
       "       [  9.],\n",
       "       [ 11.],\n",
       "       [ 13.],\n",
       "       [ 15.],\n",
       "       [ 17.],\n",
       "       [ 19.],\n",
       "       [ 21.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkTihQBcRiRMKdBGROPH/AQ/TGEE2Y7chAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f048db0d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clear plot\n",
    "plt.clf()\n",
    "\n",
    "# plot true data\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=.5)\n",
    "\n",
    "# plot predictions \n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=.5)\n",
    "\n",
    "# Legend and plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model is True:\n",
    "    # save only parameters\n",
    "    torch.save(model.state_dict(), 'saved_shitty_test_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = True\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load('saved_shitty_test_model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
